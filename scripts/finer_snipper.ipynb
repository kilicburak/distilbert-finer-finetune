{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4wyVrEMyoeh",
    "outputId": "d933a55a-983d-494d-8125-2766c4c1b899"
   },
   "source": "!pip install transformers datasets evaluate seqeval accelerate>=0.26.0 transformers[torch] matplotlib seaborn onnx huggingface-hub onnxruntime-transformers",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# Constants\n",
    "############################################\n",
    "\n",
    "# Dataset Constants\n",
    "DATASET_NAME = \"nlpaueb/finer-139\"\n",
    "CACHE_DIR = \".cache\"\n",
    "NUM_TOP_LABELS = 4\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Label Types\n",
    "LABEL_PREFIX_B = \"B-\"\n",
    "LABEL_PREFIX_I = \"I-\"\n",
    "LABEL_O = \"O\"  # Changed to string for new label set\n",
    "\n",
    "# Dataset Splits\n",
    "TRAIN_SPLIT = \"train\"\n",
    "VALIDATION_SPLIT = \"validation\"\n",
    "TEST_SPLIT = \"test\"\n",
    "\n",
    "# Output Paths\n",
    "OUTPUT_DIR_TRAIN = \"./balanced_train\"\n",
    "OUTPUT_DIR_VALIDATION = \"./balanced_validation\"\n",
    "OUTPUT_DIR_TEST = \"./balanced_test\"\n",
    "\n",
    "# Feature Names\n",
    "NER_TAGS = \"ner_tags\"\n",
    "TOKENS = \"tokens\"\n",
    "\n",
    "# Model names\n",
    "ORIGINAL_MODEL = \"distilbert-base-uncased\"\n",
    "MODEL_NAME = \"finer-selected-4-labels\"\n",
    "HUGGINGFACE_HUB_NAME = f\"sojimanatsu/{MODEL_NAME}\"\n",
    "\n",
    "# CUDA config\n",
    "CUDA_LAUNCH_BLOCKING = \"1\"\n",
    "TOKENIZERS_PARALLELISM = \"false\"\n",
    "\n",
    "#We can extend this with all the hyperparameters too."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# Simple Data Analytics For Distributions\n",
    "############################################\n",
    "\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "dataset_train = dataset[TRAIN_SPLIT].select(range(5000))\n",
    "\n",
    "# Calculate entity distribution\n",
    "entity_distribution = Counter()\n",
    "for example in dataset_train:\n",
    "    entity_distribution.update(tag for tag in example[NER_TAGS])\n",
    "\n",
    "# Remove '0' class (no entity) and get top 50 entities\n",
    "if 0 in entity_distribution:\n",
    "    del entity_distribution[0]\n",
    "top_50_entities = [entity for entity, _ in entity_distribution.most_common(50)]\n",
    "\n",
    "# Filter dataset to include only top 50 entities\n",
    "filtered_dataset = [\n",
    "    [tag for tag in example[NER_TAGS] if tag in top_50_entities] for example in dataset_train\n",
    "]\n",
    "\n",
    "# Recalculate entity distribution for top 50\n",
    "entity_distribution_top_50 = Counter()\n",
    "for tags in filtered_dataset:\n",
    "    entity_distribution_top_50.update(tags)\n",
    "\n",
    "# Absolute Entity Distribution (First 50 Labels)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(\n",
    "    [str(entity) for entity, _ in entity_distribution_top_50.most_common()],\n",
    "    [count for _, count in entity_distribution_top_50.most_common()],\n",
    "    edgecolor='black',\n",
    ")\n",
    "plt.title('Absolute Entity Distribution (First 50 Labels)')\n",
    "plt.xlabel('Entity')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, fontsize=10, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 1. Token Length Distribution\n",
    "tokens_train = [len(example[TOKENS]) for example in dataset_train]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(tokens_train, bins=30, edgecolor='black')\n",
    "plt.title('Token Length Distribution in First 5000 Samples')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2. Entity Coverage\n",
    "samples_with_entities = sum(1 for tags in filtered_dataset if tags)\n",
    "samples_without_entities = len(filtered_dataset) - samples_with_entities\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(\n",
    "    [samples_with_entities, samples_without_entities],\n",
    "    labels=[\"With Entities\", \"Without Entities\"],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    colors=[\"#ff9999\", \"#66b3ff\"]\n",
    ")\n",
    "plt.title('Entity Coverage (Top 50 Entities)')\n",
    "plt.show()\n",
    "\n",
    "# 5. Entity Co-occurrence\n",
    "co_occurrence = Counter()\n",
    "for tags in filtered_dataset:\n",
    "    unique_tags = set(tags)\n",
    "    for tag in unique_tags:\n",
    "        for other_tag in unique_tags:\n",
    "            if tag != other_tag:\n",
    "                co_occurrence[(tag, other_tag)] += 1\n",
    "\n",
    "# Prepare data for heatmap further reduce to 20 for better readability\n",
    "entity_ids = sorted(top_50_entities)[:20]\n",
    "heatmap_data = {tag: [co_occurrence.get((tag, other_tag), 0) for other_tag in entity_ids] for tag in entity_ids}\n",
    "sns.heatmap(\n",
    "    [heatmap_data[tag] for tag in entity_ids],\n",
    "    xticklabels=entity_ids,\n",
    "    yticklabels=entity_ids,\n",
    "    cmap=\"Blues\",\n",
    "    cbar_kws={\"label\": \"Co-occurrence Count\"}\n",
    ")\n",
    "plt.title('Entity Co-occurrence Heatmap (Top 50 Entities)')\n",
    "plt.xlabel('Entity')\n",
    "plt.ylabel('Entity')\n",
    "plt.show()\n",
    "\n",
    "# 6. Sentence-Level Entity Count\n",
    "entities_per_sentence = [len(tags) for tags in filtered_dataset]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(entities_per_sentence, bins=20, edgecolor='black')\n",
    "plt.title('Entity Count per Sentence (Top 50 Entities)')\n",
    "plt.xlabel('Number of Entities')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYfhkJ5jyrKY",
    "outputId": "9bd7bd4f-20ff-4501-8ce9-934a3aa7aa76"
   },
   "source": [
    "############################################\n",
    "# Create a new dataset\n",
    "############################################\n",
    "\n",
    "import random\n",
    "from datasets import load_dataset, Dataset, Features, Sequence, ClassLabel, Value\n",
    "\n",
    "############################################\n",
    "# Dataset Loading and Top-B Functions\n",
    "############################################\n",
    "\n",
    "def load_and_get_labels():\n",
    "    \"\"\"Load dataset and get original labels.\"\"\"\n",
    "    dataset = load_dataset(\n",
    "        DATASET_NAME,\n",
    "        cache_dir=CACHE_DIR,\n",
    "        keep_in_memory=True\n",
    "    )\n",
    "    original_labels = dataset[TRAIN_SPLIT].features[NER_TAGS].feature.names\n",
    "    return dataset, original_labels\n",
    "\n",
    "\n",
    "def find_top_b_labels(dataset, original_labels):\n",
    "    \"\"\"Find top B- labels with zero I- counts.\"\"\"\n",
    "    train_counts = Counter()\n",
    "    for example in dataset[TRAIN_SPLIT]:\n",
    "        train_counts.update(example[NER_TAGS])\n",
    "\n",
    "    b_and_i_counts = []\n",
    "    for label_id, label_name in enumerate(original_labels):\n",
    "        if label_name.startswith(LABEL_PREFIX_B):\n",
    "            b_count = train_counts[label_id]\n",
    "            i_label_name = label_name.replace(LABEL_PREFIX_B, LABEL_PREFIX_I)\n",
    "            i_label_id = original_labels.index(i_label_name) if i_label_name in original_labels else None\n",
    "            i_count = train_counts[i_label_id] if i_label_id is not None else 0\n",
    "\n",
    "            if i_count == 0:\n",
    "                b_and_i_counts.append((label_name, b_count, i_count))\n",
    "\n",
    "    sorted_b_and_i_counts = sorted(b_and_i_counts, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_b_and_i_counts[:NUM_TOP_LABELS]\n",
    "\n",
    "\n",
    "############################################\n",
    "# Label Mapping and Filtering Functions\n",
    "############################################\n",
    "\n",
    "def create_label_map(original_labels, selected_labels):\n",
    "    \"\"\"Create mapping from original labels to new label indices.\"\"\"\n",
    "    new_labels = [LABEL_O]\n",
    "    new_labels.extend(selected_labels)\n",
    "\n",
    "    label_map = {\n",
    "        original_labels.index(label): idx\n",
    "        for idx, label in enumerate(new_labels)\n",
    "    }\n",
    "\n",
    "    return label_map, new_labels\n",
    "\n",
    "\n",
    "def filter_and_map_labels(dataset, label_map, new_labels):\n",
    "    \"\"\"Filter examples to only keep those with selected labels and map to new label indices.\"\"\"\n",
    "\n",
    "    def process_example(example):\n",
    "        valid_indices = [\n",
    "            i for i, tag in enumerate(example[NER_TAGS])\n",
    "            if tag in label_map\n",
    "        ]\n",
    "\n",
    "        if not valid_indices:\n",
    "            return None\n",
    "\n",
    "        new_tokens = [example[TOKENS][i] for i in valid_indices]\n",
    "        new_tags = [label_map[example[NER_TAGS][i]] for i in valid_indices]\n",
    "\n",
    "        return {\n",
    "            'id': example['id'],\n",
    "            TOKENS: new_tokens,\n",
    "            NER_TAGS: new_tags\n",
    "        }\n",
    "\n",
    "    # Create new features\n",
    "    new_features = Features({\n",
    "        'id': Value('int32'),\n",
    "        TOKENS: Sequence(Value(\"string\")),\n",
    "        NER_TAGS: Sequence(ClassLabel(names=new_labels))\n",
    "    })\n",
    "\n",
    "    # Filter and map\n",
    "    filtered_dataset = dataset.map(process_example)\n",
    "    filtered_dataset = filtered_dataset.filter(lambda x: x is not None)\n",
    "\n",
    "    # Set new features\n",
    "    filtered_dataset = filtered_dataset.cast(new_features)\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "############################################\n",
    "# Count and Balance Functions\n",
    "############################################\n",
    "\n",
    "def get_min_counts(dataset, selected_label_ids):\n",
    "    \"\"\"Get minimum counts for all splits.\"\"\"\n",
    "    counts = {\n",
    "        TRAIN_SPLIT: Counter(),\n",
    "        VALIDATION_SPLIT: Counter(),\n",
    "        TEST_SPLIT: Counter()\n",
    "    }\n",
    "\n",
    "    for split in counts.keys():\n",
    "        for example in dataset[split]:\n",
    "            counts[split].update(example[NER_TAGS])\n",
    "\n",
    "    min_counts = {\n",
    "        split: min(counter[lid] for lid in selected_label_ids)\n",
    "        for split, counter in counts.items()\n",
    "    }\n",
    "\n",
    "    return min_counts\n",
    "\n",
    "\n",
    "def get_examples_with_exactly_n_occurrences(dataset, label_id, target_count):\n",
    "    \"\"\"Get examples that will give exactly n occurrences of the label.\"\"\"\n",
    "    example_counts = [\n",
    "        (idx, sum(1 for tag in example[NER_TAGS] if tag == label_id))\n",
    "        for idx, example in enumerate(dataset)\n",
    "        if label_id in example[NER_TAGS]\n",
    "    ]\n",
    "\n",
    "    random.shuffle(example_counts)\n",
    "\n",
    "    selected_indices = []\n",
    "    current_count = 0\n",
    "\n",
    "    for idx, count in example_counts:\n",
    "        if current_count + count <= target_count:\n",
    "            selected_indices.append(idx)\n",
    "            current_count += count\n",
    "        if current_count == target_count:\n",
    "            break\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "\n",
    "def create_balanced_dataset(dataset, target_count, split, label_map, new_labels):\n",
    "    \"\"\"Create balanced dataset for given split.\"\"\"\n",
    "    filtered_dataset = filter_and_map_labels(dataset[split], label_map, new_labels)\n",
    "\n",
    "    label_indices = []\n",
    "    for lid in range(1, len(new_labels)):\n",
    "        indices = get_examples_with_exactly_n_occurrences(filtered_dataset, lid, target_count)\n",
    "        label_indices.append(indices)\n",
    "\n",
    "    combined_indices = set().union(*label_indices)\n",
    "    return filtered_dataset.select(list(combined_indices))\n",
    "\n",
    "\n",
    "############################################\n",
    "# Main Execution\n",
    "############################################\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    # Load dataset and get labels\n",
    "    dataset, original_labels = load_and_get_labels()\n",
    "\n",
    "    # Find top B labels\n",
    "    top_b_labels = find_top_b_labels(dataset, original_labels)\n",
    "    selected_labels = [item[0] for item in top_b_labels]\n",
    "    print(\"Selected labels:\", selected_labels)\n",
    "\n",
    "    # Create label mapping\n",
    "    label_map, new_labels = create_label_map(original_labels, selected_labels)\n",
    "    print(\"New label set:\", new_labels)\n",
    "\n",
    "    # Get minimum counts\n",
    "    selected_label_ids = [original_labels.index(lbl) for lbl in selected_labels]\n",
    "    min_counts = get_min_counts(dataset, selected_label_ids)\n",
    "    print(\"\\nMinimum counts per split:\")\n",
    "    for split, count in min_counts.items():\n",
    "        print(f\"{split}: {count}\")\n",
    "\n",
    "    # Create balanced datasets\n",
    "    balanced_datasets = {}\n",
    "    for split in [TRAIN_SPLIT, VALIDATION_SPLIT, TEST_SPLIT]:\n",
    "        balanced_datasets[split] = create_balanced_dataset(\n",
    "            dataset,\n",
    "            min_counts[split],\n",
    "            split,\n",
    "            label_map,\n",
    "            new_labels\n",
    "        )\n",
    "\n",
    "    # Show distributions and save\n",
    "    output_dirs = {\n",
    "        TRAIN_SPLIT: OUTPUT_DIR_TRAIN,\n",
    "        VALIDATION_SPLIT: OUTPUT_DIR_VALIDATION,\n",
    "        TEST_SPLIT: OUTPUT_DIR_TEST\n",
    "    }\n",
    "\n",
    "    for split, ds in balanced_datasets.items():\n",
    "        print(f\"\\nFinal {split} distribution:\")\n",
    "        distribution = Counter()\n",
    "        for example in ds:\n",
    "            distribution.update(example[NER_TAGS])\n",
    "        for i, label in enumerate(new_labels):\n",
    "            print(f\"{label}: {distribution[i]}\")\n",
    "\n",
    "        print(f\"Total examples in {split}: {len(ds)}\")\n",
    "        ds.save_to_disk(output_dirs[split])\n",
    "        print(f\"Saved {split} dataset to {output_dirs[split]}\")\n",
    "\n",
    "\n",
    "############################################\n",
    "# Data Verification Function\n",
    "############################################\n",
    "\n",
    "def verify_datasets():\n",
    "    \"\"\"Verify the saved datasets.\"\"\"\n",
    "    dataset, original_labels = load_and_get_labels()\n",
    "    top_b_labels = find_top_b_labels(dataset, original_labels)\n",
    "    selected_labels = [item[0] for item in top_b_labels]\n",
    "    _, new_labels = create_label_map(original_labels, selected_labels)\n",
    "\n",
    "    output_dirs = {\n",
    "        TRAIN_SPLIT: OUTPUT_DIR_TRAIN,\n",
    "        VALIDATION_SPLIT: OUTPUT_DIR_VALIDATION,\n",
    "        TEST_SPLIT: OUTPUT_DIR_TEST\n",
    "    }\n",
    "\n",
    "    print(\"\\nVerifying saved datasets:\")\n",
    "    for split, path in output_dirs.items():\n",
    "        ds = Dataset.load_from_disk(path)\n",
    "        distribution = Counter()\n",
    "        for example in ds:\n",
    "            distribution.update(example[NER_TAGS])\n",
    "\n",
    "        print(f\"\\n{split} distribution:\")\n",
    "        for i, label in enumerate(new_labels):\n",
    "            print(f\"{label}: {distribution[i]}\")\n",
    "        print(f\"Total examples: {len(ds)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    verify_datasets()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6f13b869978143fb87c86ae19a666669",
      "257e0994048546bfaaa7a44bf8f91dcd",
      "43580f6150864a6697276b2a8dc7d4a4",
      "0f252c294b67488ead3233ac2aef849d",
      "6c066592ce2f45ec89ed885758968195",
      "eff0c4b3ef4e4388ad226b526a325ed6",
      "ca721d4c8a02417baa8706dd962f9e98",
      "8c5fbaa75732409d9ec29297c5d11a77",
      "fb37b95be7db49ef809d8d72eb62b44c",
      "94251265ad0546b3917bbe759ce7dd8f",
      "f25e204c102446faa8a6cf94618a6011",
      "a6ba84fcd28f471c99a22d7f3ad1ee7c",
      "c21437dc13524dbe84c3a75f76eb5557",
      "e8e9b92aad154a48b4294789e3ba3937",
      "64b38c00c6cb40ec8aa5a7a715f39e39",
      "d5592ec7060a4827bcfb8196a31faea9",
      "238ff176536e4a1ab626895fad1c6a28",
      "3d03f371f2d842569e7cda08b9eb4838",
      "027310cdb58e4a99bd8db50958bcd012",
      "0b5f168a161a4f968d62a4d836bc26d4",
      "ba468a2d68b44653932659338db933a8",
      "20f4b5c52a6440458f2d9d6c690c6520"
     ]
    },
    "id": "PWPoRXhsy0Hy",
    "outputId": "27e388e0-01c5-4b1c-d3bf-8b4b2a439f38"
   },
   "source": [
    "############################################\n",
    "# Training Block\n",
    "############################################\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_from_disk, load_dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback\n",
    "from collections import Counter\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = CUDA_LAUNCH_BLOCKING\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = TOKENIZERS_PARALLELISM\n",
    "\n",
    "# Load balanced datasets from disk\n",
    "balanced_train = load_from_disk(OUTPUT_DIR_TRAIN).shuffle()\n",
    "balanced_validation = load_from_disk(OUTPUT_DIR_VALIDATION).shuffle()\n",
    "\n",
    "\n",
    "# Debugging: Print sizes\n",
    "print(f\"Loaded Balanced Training Dataset Size: {len(balanced_train)}\")\n",
    "print(f\"Loaded Balanced Validation Dataset Size: {len(balanced_validation)}\")\n",
    "\n",
    "# Extract label mappings directly from the dataset metadata\n",
    "labels = balanced_train.features[NER_TAGS].feature.names\n",
    "print(labels)\n",
    "selected_label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2selected_label = {idx: label for idx, label in enumerate(labels)}\n",
    "\n",
    "# Tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(ORIGINAL_MODEL)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    ORIGINAL_MODEL,\n",
    "    num_labels=len(selected_label2id),\n",
    "    id2label=id2selected_label,\n",
    "    label2id=selected_label2id\n",
    ")\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[TOKENS],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[NER_TAGS]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Debugging: Check label distribution\n",
    "train_label_distribution = Counter()\n",
    "for example in balanced_train:\n",
    "    train_label_distribution.update(example[NER_TAGS])\n",
    "print(\"Training label distribution:\", train_label_distribution)\n",
    "\n",
    "validation_label_distribution = Counter()\n",
    "for example in balanced_validation:\n",
    "    validation_label_distribution.update(example[NER_TAGS])\n",
    "print(\"Validation label distribution:\", validation_label_distribution)\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_train = balanced_train.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_validation = balanced_validation.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Load data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Load metric\n",
    "metric = evaluate.load(\"seqeval\", zero_division=1)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Convert to lists and handle tensor conversion\n",
    "    true_predictions = [\n",
    "        [id2selected_label[p.item()] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2selected_label[l.item()] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",         # F1 for best model selection\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,                   # Warmup for first 10% of steps\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=8,                 \n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\",\n",
    "    logging_dir=\"./logs\",\n",
    "    push_to_hub=False,\n",
    "    save_only_model=True,\n",
    "    greater_is_better=True,             # For F1 metric\n",
    ")\n",
    "\n",
    "# Add Early Stopping callback\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2,          # Stop if no improvement for 2 epochs\n",
    "    early_stopping_threshold=0.001,     # Minimum change to qualify as improvement\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_validation,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping]\n",
    "\n",
    ")\n",
    "\n",
    "# Print features and label information for debugging\n",
    "print(\"\\nFirst example tokens:\", balanced_train[0][TOKENS])\n",
    "print(\"First example tags:\", balanced_train[0][NER_TAGS])\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save\n",
    "model.save_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained(MODEL_NAME)\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Model training and saving completed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# Review Confusion Matrix\n",
    "############################################\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 1: Select a subset of examples from the test set\n",
    "balanced_test = load_from_disk(OUTPUT_DIR_TEST)\n",
    "\n",
    "# Step 2: Select a subset of the test dataset (up to 15,000 samples)\n",
    "subset_test_set = balanced_test.select(range(min(15000, len(balanced_test))))\n",
    "\n",
    "# Tokenize and align labels for the subset test set\n",
    "tokenized_subset_test = subset_test_set.map(\n",
    "    tokenize_and_align_labels, batched=True, remove_columns=subset_test_set.column_names\n",
    ")\n",
    "\n",
    "# Step 2: Make predictions on the subset test set\n",
    "torch.cuda.empty_cache()  # Flush CUDA memory before prediction\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    predictions, labels, _ = trainer.predict(tokenized_subset_test)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Step 3: Align predictions and labels\n",
    "# Ensure that both predictions and labels have the same number of valid entries\n",
    "aligned_predictions = []\n",
    "aligned_labels = []\n",
    "\n",
    "for pred, lbl in zip(predicted_labels, labels):\n",
    "    for p, l in zip(pred, lbl):\n",
    "        if l != -100:  # Ignore special tokens\n",
    "            aligned_predictions.append(id2selected_label[p.item()])\n",
    "            aligned_labels.append(id2selected_label[l.item()])\n",
    "\n",
    "# Step 4: Create the confusion matrix\n",
    "selected_labels = balanced_test.features[\"ner_tags\"].feature.names\n",
    "\n",
    "cm = confusion_matrix(aligned_labels, aligned_predictions, labels=selected_labels)\n",
    "\n",
    "# Flush CUDA memory after processing\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Step 5: Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"YlGnBu\",\n",
    "    xticklabels=selected_labels,\n",
    "    yticklabels=selected_labels,\n",
    "    cbar_kws={'label': 'Number of Tokens'}\n",
    ")\n",
    "plt.title(\"Confusion Matrix on Test Set (2000 Examples) for Selected Labels\", fontsize=16)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "plt.ylabel(\"True Label\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# Export to ONNX\n",
    "############################################\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Define paths\n",
    "export_dir = Path(\"./onnx_model\")\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "onnx_model_path = export_dir / \"distilbert_ner.onnx\"\n",
    "\n",
    "# Load the fine-tuned PyTorch model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Export to ONNX\n",
    "dummy_input = tokenizer(\"This is a test input.\", return_tensors=\"pt\")\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    args=(dummy_input[\"input_ids\"], dummy_input[\"attention_mask\"]),\n",
    "    f=onnx_model_path,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "    },\n",
    "    opset_version=14,\n",
    "    do_constant_folding=True,\n",
    ")\n",
    "\n",
    "print(f\"ONNX model exported to {onnx_model_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "############################################\n",
    "# Utility Functions and Data Preparation\n",
    "############################################\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import time\n",
    "import psutil\n",
    "from datasets import load_from_disk\n",
    "\n",
    "def get_model_size(model_path):\n",
    "    \"\"\"Get model size in MB\"\"\"\n",
    "    if os.path.isdir(model_path):\n",
    "        total_size = sum(os.path.getsize(os.path.join(dirpath,filename)) \n",
    "                        for dirpath, dirnames, filenames in os.walk(model_path)\n",
    "                        for filename in filenames)\n",
    "    else:\n",
    "        total_size = os.path.getsize(model_path)\n",
    "    return total_size / (1024 * 1024)\n",
    "\n",
    "def get_process_memory():\n",
    "    \"\"\"Get current process memory usage in MB\"\"\"\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "def measure_memory_usage(func, name=\"Function\"):\n",
    "    \"\"\"Accurately measure CPU memory usage of a function with detailed tracking\"\"\"\n",
    "    _ = gc.collect()\n",
    "    start_mem = get_process_memory()\n",
    "    print(f\"\\n{name} - Starting memory: {start_mem:.2f} MB\")\n",
    "    \n",
    "    peak_mem = start_mem\n",
    "    def memory_monitor():\n",
    "        nonlocal peak_mem\n",
    "        current_mem = get_process_memory()\n",
    "        peak_mem = max(peak_mem, current_mem)\n",
    "        return current_mem\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = func()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    _ = gc.collect()\n",
    "    end_mem = get_process_memory()\n",
    "    execution_time = end_time - start_time\n",
    "    memory_used = end_mem - start_mem\n",
    "    \n",
    "    print(f\"{name} - Peak memory: {peak_mem:.2f} MB\")\n",
    "    print(f\"{name} - End memory: {end_mem:.2f} MB\")\n",
    "    print(f\"{name} - Memory change: {memory_used:.2f} MB\")\n",
    "    \n",
    "    return result, execution_time, memory_used, peak_mem\n",
    "\n",
    "# Load and prepare data\n",
    "balanced_test = load_from_disk(\"./balanced_test\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Extract label mappings\n",
    "selected_labels = balanced_test.features[NER_TAGS].feature.names\n",
    "selected_label2id = {label: idx for idx, label in enumerate(selected_labels)}\n",
    "selected_id2label = {idx: label for label, idx in selected_label2id.items()}\n",
    "\n",
    "def tokenize_with_labels(batch):\n",
    "    tokenized = tokenizer(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    aligned_labels = []\n",
    "    for i, labels in enumerate(batch[\"ner_tags\"]):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(labels[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        aligned_labels.append(label_ids)\n",
    "    tokenized[\"labels\"] = aligned_labels\n",
    "    return tokenized\n",
    "\n",
    "def group_by_length(tokenized_dataset):\n",
    "    grouped_batches = {}\n",
    "    for example in tokenized_dataset:\n",
    "        seq_length = len(example[\"input_ids\"])\n",
    "        if seq_length not in grouped_batches:\n",
    "            grouped_batches[seq_length] = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n",
    "        grouped_batches[seq_length][\"input_ids\"].append(example[\"input_ids\"])\n",
    "        grouped_batches[seq_length][\"attention_mask\"].append(example[\"attention_mask\"])\n",
    "        grouped_batches[seq_length][\"labels\"].append(example[\"labels\"])\n",
    "    return grouped_batches\n",
    "\n",
    "# Prepare test data\n",
    "reduced_test_set = balanced_test.select(range(min(500, len(balanced_test))))\n",
    "tokenized_test = reduced_test_set.map(tokenize_with_labels, batched=True)\n",
    "grouped_batches = group_by_length(tokenized_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# PyTorch Model Inference\n",
    "############################################\n",
    "\n",
    "# Load PyTorch model\n",
    "original_model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME).to('cpu')\n",
    "original_model.eval()\n",
    "\n",
    "pytorch_size = get_model_size(MODEL_NAME)\n",
    "print(f\"\\nPyTorch Model Size: {pytorch_size:.2f} MB\")\n",
    "\n",
    "def run_pytorch_inference():\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq_length, batch in grouped_batches.items():\n",
    "            input_ids = torch.tensor(np.array(batch[\"input_ids\"]))\n",
    "            attention_mask = torch.tensor(np.array(batch[\"attention_mask\"]))\n",
    "            labels = batch[\"labels\"]\n",
    "            \n",
    "            outputs = original_model(input_ids, attention_mask=attention_mask)\n",
    "            batch_preds = torch.argmax(outputs.logits, dim=2).numpy()\n",
    "            \n",
    "            for b in range(len(labels)):\n",
    "                valid_indices = [i for i, l in enumerate(labels[b]) if l != -100]\n",
    "                true_labels.extend([labels[b][i] for i in valid_indices])\n",
    "                predictions.extend([batch_preds[b][i] for i in valid_indices])\n",
    "    \n",
    "    return predictions, true_labels\n",
    "\n",
    "# Run PyTorch inference\n",
    "_ = gc.collect()\n",
    "initial_memory = get_process_memory()\n",
    "print(f\"Initial process memory: {initial_memory:.2f} MB\")\n",
    "\n",
    "print(\"\\nRunning PyTorch inference...\")\n",
    "(pytorch_predictions, true_labels), pytorch_time, pytorch_mem_change, pytorch_peak = measure_memory_usage(\n",
    "    run_pytorch_inference, \n",
    "    \"PyTorch\"\n",
    ")\n",
    "\n",
    "# Store metrics in global variables\n",
    "pytorch_metrics = {\n",
    "    'time': pytorch_time,\n",
    "    'memory_change': pytorch_mem_change,\n",
    "    'peak_memory': pytorch_peak,\n",
    "    'model_size': pytorch_size\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# ONNX Model Optimizer\n",
    "############################################\n",
    "\n",
    "from onnxruntime.transformers import optimizer\n",
    "\n",
    "# Specify model and optimization paths\n",
    "input_model_path = \"./onnx_model/distilbert_ner.onnx\"\n",
    "output_model_path = \"./onnx_model/distilbert_ner_optimized.onnx\"\n",
    "\n",
    "# Optimize the model\n",
    "optimized_model = optimizer.optimize_model(\n",
    "    input_model_path,\n",
    "    model_type=\"bert\",  \n",
    "    num_heads=12,       # We use the same heads with distilbert\n",
    "    hidden_size=768     # Same with distilbert model's hidden size \n",
    ")\n",
    "\n",
    "# Save the optimized model\n",
    "optimized_model.save_model_to_file(output_model_path)\n",
    "print(f\"Optimized model saved to {output_model_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# ONNX Model Inference\n",
    "############################################\n",
    "\n",
    "# Load ONNX model - GPU was disabled due to environment config with CUDA for this task.\n",
    "print(\"Available Providers:\", ort.get_available_providers())\n",
    "onnx_model_path = \"./onnx_model/distilbert_ner_optimized.onnx\"\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.enable_mem_pattern = True  # Keep memory pattern optimization enabled\n",
    "sess_options.enable_cpu_mem_arena = False  # Enable/Disable CPU memory arena\n",
    "sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL  # Use sequential execution for speed\n",
    "onnx_session = ort.InferenceSession(onnx_model_path, sess_options=sess_options, providers=['CPUExecutionProvider'])\n",
    "\n",
    "onnx_size = get_model_size(onnx_model_path)\n",
    "print(f\"\\nONNX Model Size: {onnx_size:.2f} MB\")\n",
    "\n",
    "# Pre-convert inputs to NumPy arrays\n",
    "grouped_batches = {\n",
    "    seq_length: {\n",
    "        \"input_ids\": np.asarray(batch[\"input_ids\"], dtype=np.int64),\n",
    "        \"attention_mask\": np.asarray(batch[\"attention_mask\"], dtype=np.int64),\n",
    "        \"labels\": batch[\"labels\"]\n",
    "    }\n",
    "    for seq_length, batch in grouped_batches.items()\n",
    "}\n",
    "\n",
    "def run_onnx_inference():\n",
    "    predictions = []\n",
    "    \n",
    "    # Increase batch size for better efficiency\n",
    "    batch_size = 1\n",
    "\n",
    "    for seq_length, batch in grouped_batches.items():\n",
    "        total_examples = len(batch[\"input_ids\"])\n",
    "\n",
    "        for start_idx in range(0, total_examples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, total_examples)\n",
    "            \n",
    "            # Slice batch inputs\n",
    "            input_ids = batch[\"input_ids\"][start_idx:end_idx]\n",
    "            attention_mask = batch[\"attention_mask\"][start_idx:end_idx]\n",
    "            current_labels = batch[\"labels\"][start_idx:end_idx]\n",
    "            \n",
    "            # Run inference\n",
    "            ort_inputs = {\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask\n",
    "            }\n",
    "            onnx_logits = onnx_session.run(None, ort_inputs)[0]\n",
    "            batch_preds = np.argmax(onnx_logits, axis=2)\n",
    "\n",
    "            # Collect valid predictions using NumPy vectorized operations\n",
    "            for b in range(len(current_labels)):\n",
    "                valid_indices = np.array(current_labels[b]) != -100\n",
    "                predictions.extend(batch_preds[b][valid_indices])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Run ONNX inference\n",
    "_ = gc.collect()\n",
    "initial_memory = get_process_memory()\n",
    "print(f\"Initial process memory: {initial_memory:.2f} MB\")\n",
    "\n",
    "print(\"\\nRunning ONNX inference...\")\n",
    "onnx_predictions, onnx_time, onnx_mem_change, onnx_peak = measure_memory_usage(\n",
    "    run_onnx_inference, \n",
    "    \"ONNX\"\n",
    ")\n",
    "\n",
    "# Store metrics in global variables\n",
    "onnx_metrics = {\n",
    "    'time': onnx_time,\n",
    "    'memory_change': onnx_mem_change,\n",
    "    'peak_memory': onnx_peak,\n",
    "    'model_size': onnx_size\n",
    "}\n",
    "\n",
    "# Print immediate memory usage\n",
    "current_mem = get_process_memory()\n",
    "print(f\"\\nFinal memory after ONNX inference: {current_mem:.2f} MB\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# Model Comparison\n",
    "############################################\n",
    "\n",
    "# Convert predictions to named labels\n",
    "true_labels_named = [selected_id2label[label] for label in true_labels]\n",
    "pytorch_predictions_named = [selected_id2label[pred] for pred in pytorch_predictions]\n",
    "onnx_predictions_named = [selected_id2label[pred] for pred in onnx_predictions]\n",
    "\n",
    "# Print comparative metrics\n",
    "print(\"\\nComparative Performance Metrics:\")\n",
    "print(\"\\nPyTorch Model:\")\n",
    "print(f\"Inference Time: {pytorch_metrics['time']:.2f} seconds\")\n",
    "print(f\"Memory Change: {pytorch_metrics['memory_change']:.2f} MB\")\n",
    "print(f\"Peak Memory: {pytorch_metrics['peak_memory']:.2f} MB\")\n",
    "print(f\"Model Size: {pytorch_metrics['model_size']:.2f} MB\")\n",
    "\n",
    "print(\"\\nONNX Model:\")\n",
    "print(f\"Inference Time: {onnx_metrics['time']:.2f} seconds\")\n",
    "print(f\"Memory Change: {onnx_metrics['memory_change']:.2f} MB\")\n",
    "print(f\"Peak Memory: {onnx_metrics['peak_memory']:.2f} MB\")\n",
    "print(f\"Model Size: {onnx_metrics['model_size']:.2f} MB\")\n",
    "\n",
    "# Print relative improvements\n",
    "print(\"\\nRelative Improvements (ONNX vs PyTorch):\")\n",
    "print(f\"Speed Improvement: {((pytorch_metrics['time'] - onnx_metrics['time']) / pytorch_metrics['time']) * 100:.2f}%\")\n",
    "print(f\"Memory Change Improvement: {((pytorch_metrics['memory_change'] - onnx_metrics['memory_change']) / pytorch_metrics['memory_change']) * 100:.2f}%\")\n",
    "print(f\"Peak Memory Improvement: {((pytorch_metrics['peak_memory'] - onnx_metrics['peak_memory']) / pytorch_metrics['peak_memory']) * 100:.2f}%\")\n",
    "print(f\"Model Size Improvement: {((pytorch_metrics['model_size'] - onnx_metrics['model_size']) / pytorch_metrics['model_size']) * 100:.2f}%\")\n",
    "\n",
    "# Print classification reports\n",
    "print(\"\\nPyTorch Model Performance:\")\n",
    "print(classification_report(\n",
    "    true_labels_named,\n",
    "    pytorch_predictions_named,\n",
    "    labels=selected_labels,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "print(\"\\nONNX Model Performance:\")\n",
    "print(classification_report(\n",
    "    true_labels_named,\n",
    "    onnx_predictions_named,\n",
    "    labels=selected_labels,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Compare predictions\n",
    "num_differences = sum(o != p for o, p in zip(onnx_predictions, pytorch_predictions))\n",
    "print(f\"\\nPrediction Differences:\")\n",
    "print(f\"Number of different predictions: {num_differences}\")\n",
    "print(f\"Percentage of different predictions: {(num_differences/len(onnx_predictions))*100:.2f}%\")\n",
    "\n",
    "if num_differences > 0:\n",
    "    print(\"\\nExample differences between ONNX and PyTorch predictions (first 10):\")\n",
    "    differences_shown = 0\n",
    "    for i, (o, p) in enumerate(zip(onnx_predictions_named, pytorch_predictions_named)):\n",
    "        if o != p and differences_shown < 10:\n",
    "            print(f\"Index {i}: ONNX predicted {o}, PyTorch predicted {p}\")\n",
    "            differences_shown += 1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "############################################\n",
    "# Inference Block for ONNX and Original Model\n",
    "############################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Load tokenizer and PyTorch model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "# Load ONNX session\n",
    "onnx_model_path = \"./onnx_model/distilbert_ner.onnx\"\n",
    "onnx_session = ort.InferenceSession(\n",
    "    onnx_model_path,\n",
    "    providers=['CPUExecutionProvider']  # Using CPU provider for now\n",
    ")\n",
    "\n",
    "def predict_ner_both(text):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    # PyTorch inference\n",
    "    with torch.no_grad():\n",
    "        torch_outputs = model(**inputs)\n",
    "        torch_predictions = torch.argmax(torch_outputs.logits, dim=2)[0]\n",
    "    \n",
    "    # ONNX inference\n",
    "    # Convert inputs to numpy arrays\n",
    "    onnx_inputs = {\n",
    "        'input_ids': inputs['input_ids'].numpy(),\n",
    "        'attention_mask': inputs['attention_mask'].numpy()\n",
    "    }\n",
    "    \n",
    "    # Run ONNX inference\n",
    "    onnx_outputs = onnx_session.run(None, onnx_inputs)\n",
    "    onnx_predictions = np.argmax(onnx_outputs[0], axis=2)[0]\n",
    "    \n",
    "    # Get tokens and labels\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    torch_labels = [model.config.id2label[p.item()] for p in torch_predictions]\n",
    "    onnx_labels = [model.config.id2label[p] for p in onnx_predictions]\n",
    "    \n",
    "    # Print predictions\n",
    "    print(\"\\nNER Predictions:\")\n",
    "    print(\"PyTorch vs ONNX comparison:\")\n",
    "    \n",
    "    current_word = \"\"\n",
    "    current_torch_label = None\n",
    "    current_onnx_label = None\n",
    "    \n",
    "    for token, torch_label, onnx_label in zip(tokens, torch_labels, onnx_labels):\n",
    "        if token in ['[CLS]', '[SEP]']:\n",
    "            continue\n",
    "        # If it's a subword (starts with ##)\n",
    "        if token.startswith(\"##\"):\n",
    "            current_word += token[2:]\n",
    "        else:\n",
    "            # Print the previous word if it exists\n",
    "            if current_word:\n",
    "                print(f\"{current_word}: PyTorch: {current_torch_label}, ONNX: {current_onnx_label}\")\n",
    "            current_word = token\n",
    "            current_torch_label = torch_label\n",
    "            current_onnx_label = onnx_label\n",
    "    \n",
    "    # Print the last word\n",
    "    if current_word:\n",
    "        print(f\"{current_word}: PyTorch: {current_torch_label}, ONNX: {current_onnx_label}\")\n",
    "\n",
    "# Test examples\n",
    "examples = [\n",
    "    # DebtInstrumentInterestRateStatedPercentage\n",
    "    \"The loan carries an interest rate of 5.25% per annum.\",\n",
    "    \"They secured a mortgage at 3.75% fixed rate.\",\n",
    "    \"The bond yields 4.5% annually.\",\n",
    "    \n",
    "    # LineOfCreditFacilityMaximumBorrowingCapacity\n",
    "    \"The company has a credit line of $50 million available.\",\n",
    "    \"Their revolving credit facility has a maximum borrowing capacity of $100 million.\",\n",
    "    \"The bank approved a credit line with $25 million borrowing limit.\",\n",
    "    \n",
    "    # DebtInstrumentBasisSpreadOnVariableRate1\n",
    "    \"The loan has a spread of LIBOR + 2.5%.\",\n",
    "    \"The variable rate includes a basis spread of 1.75% over prime.\",\n",
    "    \"Interest is calculated at SOFR plus 200 basis points.\",\n",
    "    \n",
    "    # AllocatedShareBasedCompensationExpense\n",
    "    \"The share-based compensation expense was $2.5 million.\",\n",
    "    \"Stock options resulted in compensation expense of $750,000.\",\n",
    "    \"They reported RSU compensation costs of $1.2 million.\"\n",
    "]\n",
    "\n",
    "# Test each example\n",
    "for text in examples:\n",
    "    print(\"\\nExample:\", text)\n",
    "    predict_ner_both(text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.notebook_login()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "output_dir = MODEL_NAME\n",
    "checkpoints = [ckpt for ckpt in os.listdir(output_dir) if ckpt.startswith(\"checkpoint-\")]\n",
    "if checkpoints:\n",
    "    last_checkpoint = max(checkpoints, key=lambda x: int(x.split(\"-\")[1]))\n",
    "    last_checkpoint_dir = os.path.join(output_dir, last_checkpoint)\n",
    "    print(f\"Last checkpoint directory: {last_checkpoint_dir}\")\n",
    "else:\n",
    "    print(\"No checkpoints found!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load the model and tokenizer from the last checkpoint\n",
    "model = AutoModelForTokenClassification.from_pretrained(last_checkpoint_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(last_checkpoint_dir)\n",
    "\n",
    "# Push the model and tokenizer to the Hugging Face Hub\n",
    "model.push_to_hub(HUGGINGFACE_HUB_NAME)\n",
    "tokenizer.push_to_hub(HUGGINGFACE_HUB_NAME)\n",
    "\n",
    "print(\"Checkpoint pushed to Hugging Face Hub!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = load_from_disk(OUTPUT_DIR_TRAIN)\n",
    "test_dataset = load_from_disk(OUTPUT_DIR_TEST)\n",
    "validation_dataset = load_from_disk(OUTPUT_DIR_VALIDATION)\n",
    "\n",
    "# Combine the datasets into a single DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": validation_dataset\n",
    "})\n",
    "\n",
    "# Save the merged dataset\n",
    "dataset_dict.save_to_disk(MODEL_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset_dict.push_to_hub(HUGGINGFACE_HUB_NAME)\n",
    "print(\"Dataset pushed to Hugging Face Hub!\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "027310cdb58e4a99bd8db50958bcd012": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b5f168a161a4f968d62a4d836bc26d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0f252c294b67488ead3233ac2aef849d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94251265ad0546b3917bbe759ce7dd8f",
      "placeholder": "",
      "style": "IPY_MODEL_f25e204c102446faa8a6cf94618a6011",
      "value": "6400/6400[00:05&lt;00:00,1270.86examples/s]"
     }
    },
    "20f4b5c52a6440458f2d9d6c690c6520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "238ff176536e4a1ab626895fad1c6a28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "257e0994048546bfaaa7a44bf8f91dcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eff0c4b3ef4e4388ad226b526a325ed6",
      "placeholder": "",
      "style": "IPY_MODEL_ca721d4c8a02417baa8706dd962f9e98",
      "value": "Map:100%"
     }
    },
    "3d03f371f2d842569e7cda08b9eb4838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43580f6150864a6697276b2a8dc7d4a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c5fbaa75732409d9ec29297c5d11a77",
      "max": 6400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb37b95be7db49ef809d8d72eb62b44c",
      "value": 6400
     }
    },
    "64b38c00c6cb40ec8aa5a7a715f39e39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba468a2d68b44653932659338db933a8",
      "placeholder": "",
      "style": "IPY_MODEL_20f4b5c52a6440458f2d9d6c690c6520",
      "value": "640/640[00:00&lt;00:00,1269.89examples/s]"
     }
    },
    "6c066592ce2f45ec89ed885758968195": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f13b869978143fb87c86ae19a666669": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_257e0994048546bfaaa7a44bf8f91dcd",
       "IPY_MODEL_43580f6150864a6697276b2a8dc7d4a4",
       "IPY_MODEL_0f252c294b67488ead3233ac2aef849d"
      ],
      "layout": "IPY_MODEL_6c066592ce2f45ec89ed885758968195"
     }
    },
    "8c5fbaa75732409d9ec29297c5d11a77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94251265ad0546b3917bbe759ce7dd8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ba84fcd28f471c99a22d7f3ad1ee7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c21437dc13524dbe84c3a75f76eb5557",
       "IPY_MODEL_e8e9b92aad154a48b4294789e3ba3937",
       "IPY_MODEL_64b38c00c6cb40ec8aa5a7a715f39e39"
      ],
      "layout": "IPY_MODEL_d5592ec7060a4827bcfb8196a31faea9"
     }
    },
    "ba468a2d68b44653932659338db933a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c21437dc13524dbe84c3a75f76eb5557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_238ff176536e4a1ab626895fad1c6a28",
      "placeholder": "",
      "style": "IPY_MODEL_3d03f371f2d842569e7cda08b9eb4838",
      "value": "Map:100%"
     }
    },
    "ca721d4c8a02417baa8706dd962f9e98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5592ec7060a4827bcfb8196a31faea9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8e9b92aad154a48b4294789e3ba3937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_027310cdb58e4a99bd8db50958bcd012",
      "max": 640,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b5f168a161a4f968d62a4d836bc26d4",
      "value": 640
     }
    },
    "eff0c4b3ef4e4388ad226b526a325ed6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f25e204c102446faa8a6cf94618a6011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb37b95be7db49ef809d8d72eb62b44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
